#!/usr/bin/env node
/**
 * Script de restauration depuis backup SQLite vers PostgreSQL local
 *
 * Ce script:
 * 1. Restaure un backup SQLite vers prisma/dev.db (temporaire)
 * 2. Migre les donn√©es vers PostgreSQL local
 * 3. Nettoie le fichier SQLite temporaire
 *
 * Usage:
 *   node scripts/restore-sqlite-backup-to-postgres.mjs [<backup_path>]
 *
 * Exemple:
 *   node scripts/restore-sqlite-backup-to-postgres.mjs prisma/dev.db.backup.2025-12-14T14-01-57
 */

import { copyFile, readdir, stat, unlink } from 'fs/promises';
import { existsSync } from 'fs';
import { fileURLToPath } from 'url';
import { dirname, join, basename } from 'path';
import { execSync } from 'child_process';
import dotenv from 'dotenv';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const rootDir = join(__dirname, '..');

// Charger .env.local et .env
dotenv.config({ path: join(rootDir, '.env.local') });
dotenv.config({ path: join(rootDir, '.env') });

const SQLITE_DB_PATH = join(rootDir, 'prisma', 'dev.db');
const POSTGRES_URL = process.env.DATABASE_URL || process.env.DATABASE_URL_LOCAL;

async function listBackups() {
  const prismaDir = join(rootDir, 'prisma');
  const files = await readdir(prismaDir);
  const backups = files
    .filter((f) => f.startsWith('dev.db.backup.'))
    .map((f) => ({
      name: f,
      path: join(prismaDir, f),
    }));

  // Trier par date (plus r√©cent en premier)
  const stats = await Promise.all(
    backups.map(async (b) => ({
      ...b,
      mtime: (await stat(b.path)).mtime,
    }))
  );

  return stats.sort((a, b) => b.mtime - a.mtime);
}

function verifyPostgresConnection() {
  if (!POSTGRES_URL) {
    throw new Error('DATABASE_URL ou DATABASE_URL_LOCAL doit √™tre d√©fini');
  }

  // V√©rifier que c'est bien PostgreSQL local
  if (!POSTGRES_URL.includes('localhost') && !POSTGRES_URL.includes('127.0.0.1')) {
    throw new Error(
      `‚ö†Ô∏è  PROTECTION: DATABASE_URL ne pointe pas vers localhost!\n` +
        `   URL actuelle: ${POSTGRES_URL.replace(/:[^:@]+@/, ':****@')}\n` +
        `   Pour restaurer vers PostgreSQL local, DATABASE_URL doit contenir localhost ou 127.0.0.1`
    );
  }

  // V√©rifier le port (devrait √™tre 5433 pour local)
  if (!POSTGRES_URL.includes(':5433') && !POSTGRES_URL.includes(':5432')) {
    console.warn(
      `‚ö†Ô∏è  ATTENTION: Port non standard d√©tect√© dans DATABASE_URL\n` +
        `   URL: ${POSTGRES_URL.replace(/:[^:@]+@/, ':****@')}`
    );
  }

  // V√©rifier qu'il n'y a pas de domaines de production
  const prodDomains = ['neon.tech', 'vercel', 'production', 'prod', 'aws'];
  const hasProdDomain = prodDomains.some((domain) => POSTGRES_URL.includes(domain));
  if (hasProdDomain) {
    throw new Error(
      `‚ö†Ô∏è  PROTECTION: DATABASE_URL contient un domaine de production!\n` +
        `   URL: ${POSTGRES_URL.replace(/:[^:@]+@/, ':****@')}\n` +
        `   Cette restauration ne peut pas pointer vers la production.`
    );
  }
}

async function getTableCounts(pool) {
  const tables = ['User', 'Project', 'Track', 'Event', 'Notification'];
  const counts = {};

  for (const table of tables) {
    try {
      const result = await pool.query(`SELECT COUNT(*) as count FROM "${table}"`);
      counts[table] = parseInt(result.rows[0].count, 10);
    } catch (err) {
      counts[table] = -1; // Erreur
    }
  }

  return counts;
}

async function main() {
  console.log('üîÑ Restauration depuis backup SQLite vers PostgreSQL local\n');

  // V√©rifier la connexion PostgreSQL
  verifyPostgresConnection();

  const backupPath = process.argv[2];

  if (!backupPath) {
    console.log('üìã Liste des backups disponibles:\n');
    const backups = await listBackups();

    if (backups.length === 0) {
      console.log('   ‚ùå Aucun backup trouv√© dans prisma/');
      console.log('\nüí° Pour cr√©er un backup:');
      console.log('   node scripts/backup-sqlite.mjs');
      process.exit(1);
    }

    console.log('   Backups disponibles:');
    backups.forEach((b, i) => {
      const sizeMB = (async () => {
        const s = await stat(b.path);
        return (s.size / 1024 / 1024).toFixed(2);
      })();
      console.log(`   ${i + 1}. ${b.name} (${b.mtime.toISOString()})`);
    });

    console.log('\nüí° Pour restaurer:');
    console.log(`   node scripts/restore-sqlite-backup-to-postgres.mjs <backup_path>`);
    console.log(`\n   Exemple:`);
    console.log(`   node scripts/restore-sqlite-backup-to-postgres.mjs ${backups[0].path}`);
    process.exit(0);
  }

  // V√©rifier que le backup existe
  if (!existsSync(backupPath)) {
    console.error(`‚ùå Backup non trouv√©: ${backupPath}`);
    process.exit(1);
  }

  // V√©rifier que c'est bien un fichier de backup
  if (!basename(backupPath).startsWith('dev.db.backup.')) {
    console.warn(`‚ö†Ô∏è  Le fichier ne semble pas √™tre un backup (dev.db.backup.*)`);
    const readline = await import('readline');
    const rl = readline.createInterface({
      input: process.stdin,
      output: process.stdout,
    });

    const answer = await new Promise((resolve) => {
      rl.question('   Continuer quand m√™me? (o/N) ', resolve);
    });
    rl.close();

    if (answer.toLowerCase() !== 'o') {
      console.log('   Restauration annul√©e');
      process.exit(0);
    }
  }

  // V√©rifier que PostgreSQL est d√©marr√©
  console.log('üîå V√©rification de PostgreSQL...');
  try {
    const pg = await import('pg');
    const { Pool } = pg;
    const pool = new Pool({ connectionString: POSTGRES_URL });
    await pool.query('SELECT 1');
    console.log('   ‚úÖ PostgreSQL connect√©');

    // Afficher les compteurs avant restauration
    console.log('\nüìä √âtat actuel de la base PostgreSQL:');
    const countsBefore = await getTableCounts(pool);
    for (const [table, count] of Object.entries(countsBefore)) {
      if (count >= 0) {
        console.log(`   ${table}: ${count} enregistrement(s)`);
      }
    }

    // Demander confirmation si la base n'est pas vide
    const totalBefore = Object.values(countsBefore).reduce((sum, c) => sum + (c > 0 ? c : 0), 0);
    if (totalBefore > 0) {
      console.log('\n‚ö†Ô∏è  ATTENTION: La base PostgreSQL contient d√©j√† des donn√©es!');
      const readline = await import('readline');
      const rl = readline.createInterface({
        input: process.stdin,
        output: process.stdout,
      });

      const answer = await new Promise((resolve) => {
        rl.question(
          '   Voulez-vous continuer? Les donn√©es existantes seront √©cras√©es. (o/N) ',
          resolve
        );
      });
      rl.close();

      if (answer.toLowerCase() !== 'o') {
        console.log('   Restauration annul√©e');
        await pool.end();
        process.exit(0);
      }
    }

    await pool.end();
  } catch (err) {
    console.error(`‚ùå Erreur de connexion PostgreSQL: ${err.message}`);
    console.error('   Assurez-vous que PostgreSQL est d√©marr√©: docker compose up -d');
    process.exit(1);
  }

  // Restaurer le backup SQLite temporairement
  console.log(`\nüì¶ Restauration du backup SQLite: ${backupPath}`);
  const backupStats = await stat(backupPath);
  console.log(`   Taille: ${(backupStats.size / 1024 / 1024).toFixed(2)} MB`);

  // Backup de la DB SQLite actuelle si elle existe
  if (existsSync(SQLITE_DB_PATH)) {
    const currentBackup = `${SQLITE_DB_PATH}.before-restore.${Date.now()}`;
    console.log(`   Backup de la DB SQLite actuelle: ${currentBackup}`);
    await copyFile(SQLITE_DB_PATH, currentBackup);
  }

  // Restaurer le backup vers SQLite temporaire
  try {
    await copyFile(backupPath, SQLITE_DB_PATH);
    console.log(`   ‚úÖ Backup restaur√© vers SQLite temporaire`);
  } catch (err) {
    console.error(`‚ùå Erreur lors de la restauration SQLite: ${err.message}`);
    process.exit(1);
  }

  // Migrer vers PostgreSQL
  console.log(`\nüöÄ Migration SQLite -> PostgreSQL...`);
  try {
    // Utiliser le script de migration existant
    execSync(`node scripts/migrate-sqlite-to-postgres.mjs`, {
      stdio: 'inherit',
      cwd: rootDir,
      env: { ...process.env, DATABASE_URL: POSTGRES_URL },
    });
  } catch (err) {
    console.error(`‚ùå Erreur lors de la migration: ${err.message}`);
    // Ne pas supprimer le SQLite temporaire en cas d'erreur
    process.exit(1);
  }

  // V√©rifier les compteurs apr√®s migration
  console.log(`\nüìä √âtat apr√®s restauration:`);
  try {
    const pg = await import('pg');
    const { Pool } = pg;
    const pool = new Pool({ connectionString: POSTGRES_URL });
    const countsAfter = await getTableCounts(pool);
    for (const [table, count] of Object.entries(countsAfter)) {
      if (count >= 0) {
        console.log(`   ${table}: ${count} enregistrement(s)`);
      }
    }
    await pool.end();
  } catch (err) {
    console.warn(`‚ö†Ô∏è  Impossible de v√©rifier les compteurs: ${err.message}`);
  }

  // Nettoyer le SQLite temporaire (optionnel, on peut le garder pour debug)
  console.log(`\nüßπ Nettoyage...`);
  const keepSqlite = process.argv.includes('--keep-sqlite');
  if (!keepSqlite) {
    try {
      await unlink(SQLITE_DB_PATH);
      console.log(`   ‚úÖ Fichier SQLite temporaire supprim√©`);
    } catch (err) {
      console.warn(`   ‚ö†Ô∏è  Impossible de supprimer le SQLite temporaire: ${err.message}`);
      console.warn(`   Vous pouvez le supprimer manuellement: rm ${SQLITE_DB_PATH}`);
    }
  } else {
    console.log(`   ‚ÑπÔ∏è  Fichier SQLite temporaire conserv√© (--keep-sqlite)`);
  }

  console.log(`\n‚úÖ Restauration termin√©e avec succ√®s!`);
}

main().catch((err) => {
  console.error(`\n‚ùå Erreur fatale: ${err.message}`);
  console.error(err.stack);
  process.exit(1);
});
